{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Bidirectional, RepeatVector, TimeDistributed\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " #function to read raw text file\n",
    "def read_text(filename):\n",
    "    # open the file\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define a function to split the text into English-German pairs separated by '\\n' and then split these pairs into English sentences and German sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lines(text):\n",
    "    sents = text.strip().split('\\n')\n",
    "    sents = [i.split('\\t') for i in sents]\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_text(\"deu.txt\")\n",
    "deu_eng = to_lines(data)\n",
    "deu_eng = array(deu_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "deu_eng = deu_eng[:2000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Hi.', 'Hallo!'],\n",
       "       ['Hi.', 'Grüß Gott!'],\n",
       "       ['Run!', 'Lauf!'],\n",
       "       ...,\n",
       "       ['I never win.', 'Ich gewinne nie.'],\n",
       "       ['I often ski.', 'Ich fahre oft Ski.'],\n",
       "       ['I oppose it.', 'Ich bin dagegen.']], dtype='<U537')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deu_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]]\n",
    "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Hi', 'Hallo'],\n",
       "       ['Hi', 'Grüß Gott'],\n",
       "       ['Run', 'Lauf'],\n",
       "       ...,\n",
       "       ['I never win', 'Ich gewinne nie'],\n",
       "       ['I often ski', 'Ich fahre oft Ski'],\n",
       "       ['I oppose it', 'Ich bin dagegen']], dtype='<U537')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deu_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lowercase\n",
    "for i in range(len(deu_eng)):\n",
    "    deu_eng[i,0] = deu_eng[i,0].lower()\n",
    "    \n",
    "    deu_eng[i,1] = deu_eng[i,1].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['hi', 'hallo'],\n",
       "       ['hi', 'grüß gott'],\n",
       "       ['run', 'lauf'],\n",
       "       ...,\n",
       "       ['i never win', 'ich gewinne nie'],\n",
       "       ['i often ski', 'ich fahre oft ski'],\n",
       "       ['i oppose it', 'ich bin dagegen']], dtype='<U537')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deu_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text to Sequence Conversion\n",
    "To feed our data in a Seq2Seq model, we will have to convert both the input and the output sentences into integer sequences of fixed length. Before that, let's visualise the length of the sentences. We will capture the lengths of all the sentences in two separate lists for English and German, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty lists\n",
    "eng_l = []\n",
    "deu_l = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in deu_eng[:,0]:\n",
    "    eng_l.append(len(i.split()))\n",
    "\n",
    "for i in deu_eng[:,1]:\n",
    "    deu_l.append(len(i.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum length of the German sentences is 11 and that of the English phrases is 8.\n",
    "\n",
    "Let's vectorize our text data by using Keras's Tokenizer() class. It will turn our sentences into sequences of integers. Then we will pad those sequences with zeros to make all the sequences of same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build a tokenizer\n",
    "def tokenization(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 671\n"
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = tokenization(deu_eng[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "eng_length = 8\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deutch Vocabulary Size: 1148\n"
     ]
    }
   ],
   "source": [
    "# prepare Deutch tokenizer\n",
    "deu_tokenizer = tokenization(deu_eng[:, 1])\n",
    "deu_vocab_size = len(deu_tokenizer.word_index) + 1\n",
    "\n",
    "deu_length = 8\n",
    "print('Deutch Vocabulary Size: %d' % deu_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # integer encode sequences\n",
    "    seq = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building\n",
    "We will now split the data into train and test set for model training and evaluation, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(deu_eng, test_size=0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to encode the sentences. We will encode German sentences as the input sequences and English sentences as the target sequences. It will be done for both train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "trainX = encode_sequences(deu_tokenizer, deu_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare validation data\n",
    "testX = encode_sequences(deu_tokenizer, deu_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the exciting part! Let us define our Seq2Seq model architecture. We are using an Embedding layer and an LSTM layer as our encoder and another LSTM layer followed by a Dense layer as the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build NMT model\n",
    "def build_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(RepeatVector(out_timesteps))\n",
    "    model.add(LSTM(units, return_sequences=True))\n",
    "    model.add(Dense(out_vocab, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = build_model(deu_vocab_size, eng_vocab_size, deu_length, eng_length, 512)\n",
    "rms = optimizers.RMSprop(lr=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that we have used 'sparse_categorical_crossentropy' as the loss function because it allows us to use the target sequence as it is instead of one hot encoded format. One hot encoding the target sequences with such a huge vocabulary might consume our system's entire memory.\n",
    "\n",
    "It seems we are all set to start training our model. We will train it for 30 epochs and with a batch size of 512. You may change and play these hyperparameters. We will also be using ModelCheckpoint() to save the best model with lowest validation loss. I personally prefer this method over early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 1280 samples, validate on 320 samples\n",
      "Epoch 1/10\n",
      "1280/1280 [==============================] - 9s 7ms/step - loss: 6.2550 - val_loss: 2.4804\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.48042, saving model to model.h1\n",
      "Epoch 2/10\n",
      "1280/1280 [==============================] - 3s 3ms/step - loss: 2.2683 - val_loss: 2.1014\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.48042 to 2.10144, saving model to model.h1\n",
      "Epoch 3/10\n",
      "1280/1280 [==============================] - 3s 3ms/step - loss: 1.9506 - val_loss: 1.9976\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.10144 to 1.99764, saving model to model.h1\n",
      "Epoch 4/10\n",
      "1280/1280 [==============================] - 5s 4ms/step - loss: 1.8469 - val_loss: 1.9438\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.99764 to 1.94381, saving model to model.h1\n",
      "Epoch 5/10\n",
      "1280/1280 [==============================] - 5s 4ms/step - loss: 1.7881 - val_loss: 1.9218\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.94381 to 1.92183, saving model to model.h1\n",
      "Epoch 6/10\n",
      "1280/1280 [==============================] - 3s 3ms/step - loss: 1.7732 - val_loss: 2.0225\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.92183\n",
      "Epoch 7/10\n",
      "1280/1280 [==============================] - 5s 4ms/step - loss: 1.7811 - val_loss: 1.8729\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.92183 to 1.87290, saving model to model.h1\n",
      "Epoch 8/10\n",
      "1280/1280 [==============================] - 5s 4ms/step - loss: 1.6914 - val_loss: 1.8409\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.87290 to 1.84091, saving model to model.h1\n",
      "Epoch 9/10\n",
      "1280/1280 [==============================] - 3s 3ms/step - loss: 1.6473 - val_loss: 1.8302\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.84091 to 1.83025, saving model to model.h1\n",
      "Epoch 10/10\n",
      "1280/1280 [==============================] - 5s 4ms/step - loss: 1.6738 - val_loss: 1.7948\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.83025 to 1.79478, saving model to model.h1\n"
     ]
    }
   ],
   "source": [
    "filename = 'model.h1'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n",
    "          epochs=10, batch_size=512, \n",
    "          validation_split = 0.2,\n",
    "          callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Predictions\n",
    "Let's load the saved model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model.h1')\n",
    "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(n, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == n:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert predictions into text (English)\n",
    "preds_text = []\n",
    "for i in preds:\n",
    "    temp = []\n",
    "    for j in range(len(i)):\n",
    "        t = get_word(i[j], eng_tokenizer)\n",
    "        if j > 0:\n",
    "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)\n",
    "             \n",
    "        else:\n",
    "            if(t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)            \n",
    "        \n",
    "    preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kiss tom</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>let tom in</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>forget it</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>were lazy</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i love snow</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        actual predicted\n",
       "0     kiss tom  i       \n",
       "1   let tom in  i       \n",
       "2    forget it  i       \n",
       "3    were lazy  i       \n",
       "4  i love snow  i       "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.manythings.org/anki/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
